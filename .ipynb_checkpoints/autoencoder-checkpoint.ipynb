{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67ff721e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tifffile as tiff\n",
    "from glob import glob\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torchvision.io import read_image\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skimage import io\n",
    "import cv2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, accuracy_score, f1_score, balanced_accuracy_score, precision_score, recall_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils import compute_sample_weight\n",
    "from optuna.pruners import SuccessiveHalvingPruner\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPU...\")\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    print(\"Using CPU...\")\n",
    "    dev = \"cpu\"\n",
    "    \n",
    "    \n",
    "device = torch.device(dev)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Set the random seed for reproducibility \n",
    "torch.manual_seed(2020) \n",
    "\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            # Transform the 28 by 28 image to an embedded code size of 30\n",
    "            nn.Linear(38400, 30),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(30, 38400),\n",
    "            nn.Sigmoid()  #to range [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x will be a (batch_size,1,28,28) tensor when using MNIST\n",
    "        # so we will reshape it to a (batch_size, 28*28) flat tensor.\n",
    "        # After it has been decoded we will reshape back to the image shape.\n",
    "        x = self.encoder(x.view(-1, 38400))\n",
    "        x = self.decoder(x)\n",
    "        return x.view(-1, 1, 160, 240)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            # 1 input image channel, 16 output channel, 3x3 square convolution\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),  # activation function\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),  # conv layer\n",
    "            nn.ReLU(), # activation function \n",
    "            nn.Conv2d(32, 64, kernel_size=7, stride=1, padding=0) # conv layer\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=7, stride=1, padding=0), # conv transpose layer\n",
    "            nn.ReLU(), # activation function\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), # conv transpose layer\n",
    "            nn.ReLU(), # activation function\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()  #to range [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ConvAutoencoder2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder2D, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            # 1 input image channel, 16 output channel, 3x3 square convolution\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),  # activation function\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),  # conv layer\n",
    "            nn.ReLU(), # activation function \n",
    "            nn.Conv2d(32, 64, kernel_size=7, stride=1, padding=0), # conv layer\n",
    "            nn.ReLU(),\n",
    "            #nn.Linear( 64*1*1, 2)\n",
    "            nn.Linear( 64*1*1, 2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            \n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=7, stride=1, padding=0), # conv transpose layer\n",
    "            nn.ReLU(), # activation function\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), # conv transpose layer\n",
    "            nn.ReLU(), # activation function\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()  #to range [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1c0287",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgA = './UCSD_Anomaly_Dataset.v1p2/UCSDped1/Test_all/Test017_141.tif'\n",
    "imgB = './UCSD_Anomaly_Dataset.v1p2/UCSDped1/Test_all/Test017_143.tif'\n",
    "\n",
    "\n",
    "imlist = [imgA,imgB]\n",
    "\n",
    "w,h=Image.open(imlist[0]).size\n",
    "N=len(imlist)\n",
    "\n",
    "arr=np.zeros((h,w),float)\n",
    "\n",
    "\n",
    "for im in imlist:\n",
    "    imarr=np.array(Image.open(im),dtype=float)\n",
    "    arr=arr+imarr/N\n",
    "\n",
    "\n",
    "arr=np.array(np.round(arr),dtype=np.uint8)\n",
    "\n",
    "out=Image.fromarray(arr)\n",
    "#out.save(\"017_142.tif\")\n",
    "#out.show()\n",
    "\n",
    "\n",
    "path = './UCSD_Anomaly_Dataset.v1p2/UCSDped1/Test_all'\n",
    "imageList = [os.path.join(path, file) for file in os.listdir(path)]\n",
    "print(imageList[0])\n",
    "\n",
    "w,h=Image.open(imageList[0]).size\n",
    "N=len(imageList)\n",
    "\n",
    "avgArr=np.zeros((h,w),float)\n",
    "\n",
    "for im in imageList:\n",
    "    imageArr=np.array(Image.open(im),dtype=float)\n",
    "    avgArr=avgArr+imageArr/N\n",
    "    \n",
    "avgArr=np.array(np.round(avgArr),dtype=np.uint8)\n",
    "    \n",
    "avg=Image.fromarray(avgArr)\n",
    "#avg.save(\"Test_avg.tif\")\n",
    "avg.show()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "292923ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 200, 160, 240)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "\"\"\"\n",
    "class AnomalyDataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.folder_names = os.listdir(self.img_dir)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.folder_names)\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #img_path = self.img_dir[index]\n",
    "        #image = Image.open(img_path)\n",
    "        #avg = Image.open('Test_avg.tif')\n",
    "        #image1 = np.asarray(image)\n",
    "        #image2 = np.asarray(avg)\n",
    "        #image = image1 - image2\n",
    "        #image = Image.fromarray(image)\n",
    "        #image.show()\n",
    "        #if self.transform:\n",
    "        #    image = self.transform(image)\n",
    "        \n",
    "        folder_path = os.path.join(self.img_dir, self.folder_names[index])\n",
    "        image_filenames = os.listdir(folder_path)\n",
    "        \n",
    "        images = []\n",
    "        for img in image_filenames:\n",
    "            if img.endswith('.tif'):\n",
    "                image_path = os.path.join(folder_path, img)\n",
    "                image = Image.open(image_path)\n",
    "            \n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                images.append(image)\n",
    "            \n",
    "        return images\n",
    "      \n",
    "      \n",
    "\"\"\"   \n",
    "\n",
    "        \n",
    "path = './UCSD_Anomaly_Dataset.v1p2/UCSDped1/All_data'\n",
    "data_transforms = transforms.Compose([transforms.Resize((160, 240)), transforms.ToTensor()])\n",
    "\n",
    "#dataset = AnomalyDataset(path, data_transforms)\n",
    "\n",
    "\n",
    "\n",
    "#dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "root_dir = './UCSD_Anomaly_Dataset.v1p2/UCSDped1/All_data'\n",
    "num_folders = 70\n",
    "num_images_per_folder = 200\n",
    "image_height = 160\n",
    "image_width = 240\n",
    "\n",
    "dataset = np.zeros((num_folders, num_images_per_folder, image_height, image_width))\n",
    "\n",
    "for i in range(num_folders):\n",
    "    folder_name = str(i+1).zfill(3)\n",
    "    folder_path = os.path.join(root_dir, folder_name)\n",
    "\n",
    "    for j in range(num_images_per_folder):\n",
    "        image_name = str(j+1).zfill(3) + '.tif'\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "        image = image.resize((240, 160))\n",
    "        \n",
    "        image = np.array(image)\n",
    "        dataset[i, j, :, :] = image\n",
    "    \n",
    "    \n",
    "    \n",
    "print(dataset.shape)\n",
    "dataset_norm = dataset/255.0\n",
    "\n",
    "#dataset_tensor = torch.tensor(dataset)\n",
    "#print(dataset_tensor.shape)\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "#image_path_train = './UCSD_Anomaly_Dataset.v1p2/UCSDped1/Train_all'\n",
    "#image_paths_train = glob(image_path_train + '/*.tif')\n",
    "#data_transforms = transforms.Compose([transforms.Resize((160, 240)), transforms.ToTensor()])\n",
    "\n",
    "\n",
    "\n",
    "#image_path_test = './UCSD_Anomaly_Dataset.v1p2/UCSDped1/Test_all'\n",
    "#image_paths_test = glob(image_path_test + '/*.tif')\n",
    "\n",
    "#dataset_train = AnomalyDataset(image_paths_train, data_transforms)\n",
    "#dataset_train2 = AnomalyDataset(image_paths_test, data_transforms)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#dataset = UCSDAnomalyDataset('./UCSD_Anomaly_Dataset.v1p2/UCSDped1/Train', time_stride=1)\n",
    "#data_train = data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48ede3b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 200, 1)\n"
     ]
    }
   ],
   "source": [
    "label_start = 34\n",
    "labels = np.zeros((num_folders, num_images_per_folder, 1))\n",
    "\"\"\"    \n",
    "labels = np.zeros(7200, dtype=np.int8)\n",
    "import csv\n",
    "with open('labels.txt', 'r') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        if(\",\" in line):\n",
    "            #part1 = line.rstrip().split(',')[0]\n",
    "            #part2 = line.rstrip().split(',')[1]\n",
    "            start1 = int(line.rstrip().split(',')[0].split(':')[0])-1+(i*200)\n",
    "            end1 = int(line.rstrip().split(',')[0].split(':')[1])+1+(i*200)\n",
    "            \n",
    "            labels[start1:end1] = 1\n",
    "            \n",
    "            start2 = int(line.rstrip().split(',')[1].split(':')[0])-1+(i*200)\n",
    "            end2 = int(line.rstrip().split(',')[1].split(':')[1].replace(';', ''))+1+(i*200)\n",
    "            \n",
    "            labels[start2:end2] = 1\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            start3 = int(line.rstrip().split(';')[0].split(':')[0])-1+(i*200)\n",
    "            end3 = int(line.rstrip().split(';')[0].split(':')[1])+1+(i*200)\n",
    "            #s = slice(*map(int, frames.split(':')))\n",
    "            #print(s)\n",
    "            labels[start3:end3] = 1\n",
    "            \n",
    "\"\"\"\n",
    "            \n",
    "            \n",
    "            \n",
    "with open(\"labels.txt\", \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        parts = line.strip().split(\";\")\n",
    "        if (\",\" in line):\n",
    "            indices = parts[0].strip().split(\",\")\n",
    "            for index in indices:\n",
    "                start, end = index.strip().split(\":\")\n",
    "                start = int(start) - 1\n",
    "                end = int(end) - 1\n",
    "                \n",
    "                labels[i+label_start, start:end, 0] = 1\n",
    "        else:\n",
    "            start, end = parts[0].strip().split(\":\")\n",
    "            start = int(start) - 1\n",
    "            end = int(end) - 1\n",
    "            \n",
    "            labels[i+label_start, start:end, 0] = 1\n",
    "                \n",
    "                \n",
    "                \n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c65e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_AE(model, dataset, max_epochs=20, print_steps=5):\n",
    "    #Training (optimisation) parameters\n",
    "    batch_size=64\n",
    "    learning_rate=1e-3\n",
    "\n",
    "    #Choose mean square error loss\n",
    "    criterion = nn.MSELoss() \n",
    "\n",
    "    #Choose the Adam optimiser\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "    #Specify how the data will be loaded in batches (with random shuffling)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    #Storage\n",
    "    outputs = []\n",
    "    \n",
    "    model.to(device)\n",
    "    #train_loader = train_loader.cuda()\n",
    "\n",
    "    #Start training\n",
    "    for epoch in range(max_epochs):\n",
    "        for img in train_loader:\n",
    "            img = img.to(device)\n",
    "            recon = model(img.float())\n",
    "            #print(recon.shape)\n",
    "            loss = criterion(recon, img.to(device))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()  \n",
    "            optimizer.zero_grad()\n",
    "          \n",
    "        #if ((epoch % print_steps) == 0) or (epoch +1 == max_epochs):\n",
    "        print('Epoch:{}, Loss:{:.4f}'.format(epoch+1, loss.item()))\n",
    "        outputs.append((epoch, img.detach(), recon.detach()),)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6d5d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ddd7a1a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 200, 1)\n",
      "==========PCA TRAIN/TEST==========\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset_norm, labels, test_size=0.2, random_state=42)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "#img = Image.fromarray(np.uint8(X_train[0][0]))\n",
    "\n",
    "#plt.imshow(img)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#cae.to(device)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def do_pca(n_components, train_data, test_data):\n",
    "    pca = PCA(n_components)\n",
    "    \n",
    "    #train_data = train_data.numpy()\n",
    "    num_videos, num_frames, height, width = train_data.shape\n",
    "    data_train = train_data.reshape(num_videos*num_frames, height*width)\n",
    "    print(data_train.shape)\n",
    "    \n",
    "    transformed_train_images = pca.fit_transform(data_train)\n",
    "    reconstructed_train_images = pca.inverse_transform(transformed_train_images)\n",
    "    print(reconstructed_train_images.shape)\n",
    "    \n",
    "    #test_data = test_data.numpy()\n",
    "    num_videos, num_frames, height, width = test_data.shape   \n",
    "    data_test = test_data.reshape(num_videos*num_frames, height*width)\n",
    "    transformed_test_images = pca.transform(data_test)\n",
    "    reconstructed_test_images = pca.inverse_transform(transformed_test_images)\n",
    "    \n",
    "\n",
    "    #print(np.cumsum(pca.explained_variance_ratio_))\n",
    "\n",
    "    plt.plot(np.arange(1,n_components+1), pca.explained_variance_ratio_)\n",
    "    # Plotting using a log scale might show more information\n",
    "    #plt.yscale('log')\n",
    "    plt.ylabel('Explained Variance Ratio')\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(np.arange(1,n_components+1), np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    reconstruction_error_train = mean_squared_error(data_train, reconstructed_train_images)\n",
    "    print('Train Reconstruction error is ', reconstruction_error_train)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    plt.figure(figsize=(16, 4))\n",
    "    for i in range(8):\n",
    "        # Top row: show original faces\n",
    "        plt.subplot(2,8,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(data_train[i].reshape(160,240), cmap='Greys_r')\n",
    "        # Bottom row: show reconstructions\n",
    "        plt.subplot(2,8, 8+i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(reconstructed_train_images[i].reshape(160,240), cmap='Greys_r')\n",
    "    plt.show()\n",
    "    \n",
    "    reconstruction_error_test = mean_squared_error(data_test, reconstructed_test_images)\n",
    "    print('Test Reconstruction error is ', reconstruction_error_test)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    plt.figure(figsize=(16, 4))\n",
    "    for i in range(8):\n",
    "        # Top row: show original faces\n",
    "        plt.subplot(2,8,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(data_test[i].reshape(160,240), cmap='Greys_r')\n",
    "        # Bottom row: show reconstructions\n",
    "        plt.subplot(2,8, 8+i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(reconstructed_test_images[i].reshape(160,240), cmap='Greys_r')\n",
    "    plt.show()\n",
    "    \n",
    "    return transformed_train_images, transformed_test_images\n",
    "\n",
    "    \n",
    "    \n",
    "print(\"==========PCA TRAIN/TEST==========\")\n",
    "#pca_100_train, pca_100_test = do_pca(100, X_train, X_test)\n",
    "#pca_200_train, pca_200_test = do_pca(200, X_train, X_test)\n",
    "#pca_400_train, pca_400_test = do_pca(400, X_train, X_test)\n",
    "#pca_600_train, pca_600_test = do_pca(600, X_train, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1bb91c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ae = Autoencoder()\n",
    "cae = ConvAutoencoder()\n",
    "cae2D = ConvAutoencoder2D()\n",
    "\n",
    "#print(ae)\n",
    "#print(\"==============Standard Autoencoder===========\")\n",
    "#outputs = train_AE(ae, dataset, max_epochs=30, print_steps=30)\n",
    "#print(\"\\n\\n\")\n",
    "\n",
    "\"\"\"\n",
    "numImgs=12;\n",
    "for k in range(0, len(outputs), 9):\n",
    "    plt.figure(figsize=(numImgs, 2))\n",
    "    imgs = outputs[k][1].numpy()    \n",
    "    recon = outputs[k][2].numpy()\n",
    "    print('Epoch:', k+1)\n",
    "    for i, item in enumerate(imgs):\n",
    "        if i >= numImgs: break\n",
    "        plt.subplot(2, numImgs, i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(item[0])\n",
    "        \n",
    "    for i, item in enumerate(recon):\n",
    "        if i >= numImgs: break\n",
    "        plt.subplot(2, numImgs, numImgs+i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(item[0])\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(\"==============ConvAutoencoder TRAIN==============\")\n",
    "outputs = train_AE(cae, X_train, max_epochs=30, print_steps=30)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "print(\"\\n\\n\")\n",
    "print(\"==============ConvAutoencoder TEST==============\")\n",
    "outputs = train_AE(cae, X_test, max_epochs=30, print_steps=30)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "numOut = len(outputs)-1\n",
    "numImgs=12;\n",
    "for k in range(0, len(outputs), 9):\n",
    "    plt.figure(figsize=(numImgs, 2))\n",
    "    imgs = outputs[k][1].cpu().numpy()    \n",
    "    recon = outputs[k][2].cpu().numpy()\n",
    "    print('Epoch:', k+1)\n",
    "    for i, item in enumerate(imgs):\n",
    "        if i >= numImgs: break\n",
    "        plt.subplot(2, numImgs, i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(item[0])\n",
    "        \n",
    "    for i, item in enumerate(recon):\n",
    "        if i >= numImgs: break\n",
    "        plt.subplot(2, numImgs, numImgs+i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(item[0])\n",
    "        \n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "imgs = outputs[numOut][1].cpu().numpy()    \n",
    "recon = outputs[numOut][2].cpu().numpy()\n",
    "\n",
    "for i in range(8):\n",
    "    # Top row: show original faces\n",
    "    plt.subplot(2,8,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(imgs[i][0].reshape(160,240), cmap='Greys_r')\n",
    "    # Bottom row: show reconstructions\n",
    "    plt.subplot(2,8, 8+i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(recon[i][0].reshape(160,240), cmap='Greys_r')\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55fc995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e82334",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class LinearRegression(torch.nn.Module):\n",
    "\n",
    "    def __init__(self): \n",
    "        super(LinearRegression, self).__init__() \n",
    "        self.linear = torch.nn.Linear(38400, 1)\n",
    "\n",
    "      \n",
    "    def forward(self, x): \n",
    "\n",
    "        predict_y = self.linear(x) \n",
    "        return predict_y\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f207e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainLinearModel(model, dataset, labels, max_epochs=20, print_steps=5):\n",
    "    #Training (optimisation) parameters\n",
    "    learning_rate=1e-3\n",
    "\n",
    "    #Choose mean square error loss\n",
    "    criterion = nn.MSELoss() \n",
    "\n",
    "    \n",
    "    #Choose the Adam optimiser\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    labels = torch.from_numpy(labels)\n",
    "    images = torch.from_numpy(dataset)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    #Storage\n",
    "    outputs = []\n",
    "    \n",
    "    model.to(device)\n",
    "\n",
    "    #Start training\n",
    "    for epoch in range(max_epochs):\n",
    "        for img, label in images:\n",
    "            img = img.to(device)\n",
    "            predict = model(img.float())\n",
    "            #print(recon.shape)\n",
    "            loss = criterion(predict, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()  \n",
    "            optimizer.zero_grad()\n",
    "          \n",
    "        #if ((epoch % print_steps) == 0) or (epoch +1 == max_epochs):\n",
    "        print('Epoch:{}, Loss:{:.4f}'.format(epoch+1, loss.item()))\n",
    "        outputs.append((epoch, img.detach(), recon.detach()),)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba1eeae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(outputs[29][1].cpu().numpy().shape)\n",
    "#print(outputs[29][])\n",
    "#print(pca_400.shape)\n",
    "\n",
    "#linearModel = LinearRegression()\n",
    "\n",
    "#linearOutputs = trainLinearModel(linearModel, pca_400, labels, 50, 50)\n",
    "\n",
    "V, F = y_train.shape[:2]\n",
    "labels_train = np.reshape(y_train, (V*F, 1))\n",
    "\n",
    "V, F = y_test.shape[:2]\n",
    "labels_test = np.reshape(y_test, (V*F, 1))\n",
    "labels_test_log = labels_test.ravel()\n",
    "labels_train_log = labels_train.ravel()\n",
    "\n",
    "linearPCA = RidgeClassifier().fit(pca_400_train, labels_train_log)\n",
    "\n",
    "y_pred = linearPCA.predict(pca_400_test)\n",
    "accuracy = balanced_accuracy_score(labels_test_log, y_pred)\n",
    "print(\"Accuracy of Ridge Classifier: \", accuracy)\n",
    "auc = roc_auc_score(labels_test_log, y_pred)\n",
    "print(\"AUC score for Ridge Classifier: \", auc)\n",
    "print(\"F1 score for Ridge Classfier\", f1_score(labels_test_log, y_pred))\n",
    "\n",
    "#linearPCA.score(pca_400_test, labels_test)\n",
    "\n",
    "\n",
    "clf = LogisticRegression().fit(pca_400_train, labels_train_log)\n",
    "pred = clf.predict(pca_400_test)\n",
    "acc = balanced_accuracy_score(labels_test_log, pred)\n",
    "\n",
    "print(\"Accuracy of Logistic regression: \", acc)\n",
    "auc_log = roc_auc_score(labels_test_log, pred)\n",
    "print(\"AUC score for Logistic regression: \", auc_log)\n",
    "print(\"F1 score for Logistic regression\", f1_score(labels_test_log, pred))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#linearAE = RidgeClassifier().fit(outputs[29][1].cpu().numpy().flatten().reshape(-1, 1), labels)\n",
    "#linearAE.score(outputs[29][1].cpu().numpy(), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d658c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "\n",
    "class ESN(BaseEstimator):\n",
    "    def __init__(self, input_size, reservoir_size, output_size, leaking_rate=0.95, spectral_radius=1, input_scaling=1, threshold=0.5, sparsity=0.1, ridge_alpha=0.5, random_seed=75):\n",
    "        np.random.seed(random_seed)\n",
    "        self.input_size = input_size\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.W_in = np.random.randn(reservoir_size, input_size)\n",
    "        self.W_res = np.random.randn(reservoir_size, reservoir_size)\n",
    "        #self.W_out = np.random.randn(output_size, reservoir_size)\n",
    "        \n",
    "        self.leaking_rate = leaking_rate\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.input_scaling = input_scaling\n",
    "        self.threshold = threshold\n",
    "        self.sparsity = sparsity\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "        \n",
    "        e, v = np.linalg.eig(self.W_res)\n",
    "        max_abs = np.max(np.abs(e))\n",
    "        self.W_res = self.W_res/max_abs\n",
    "        M = (np.random.uniform(size=(reservoir_size, reservoir_size)) < self.sparsity) * 1.0\n",
    "        self.W_res *= M\n",
    "        \n",
    "        self.h0 = np.zeros((reservoir_size, 1))\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def update(self, x):\n",
    "        h = self.h0\n",
    "        T = x.shape[0]\n",
    "        states = np.zeros((T, self.reservoir_size))\n",
    "\n",
    "        for t in range(T):\n",
    "            #print(x[t].reshape(-1, 1).shape)\n",
    "            h = self.leaking_rate * np.tanh(self.spectral_radius * self.W_res @ h + self.input_scaling * self.W_in @ \n",
    "                                                                                 x[t].reshape(-1, 1)) + (1-self.leaking_rate)*h\n",
    "            \n",
    "            states[t] = h.flatten()\n",
    "            \n",
    "        #print(states.shape)\n",
    "        \n",
    "        return states\n",
    "    \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        V, F, D = X.shape\n",
    "        self.W_out = np.random.randn(self.output_size, self.reservoir_size)\n",
    "        states = np.zeros((V, F, self.reservoir_size))\n",
    "        \n",
    "        for v in range(V):\n",
    "            states[v] = self.update(X[v])\n",
    "        \n",
    "        states = states.reshape(V*F, self.reservoir_size)\n",
    "        \n",
    "            \n",
    "        \n",
    "        ridge = Ridge(alpha=self.ridge_alpha)\n",
    "        weights = compute_sample_weight(class_weight='balanced', y=y.flatten())\n",
    "        ridge.fit(states, y.flatten(), sample_weight=weights)\n",
    "        self.W_out = ridge.coef_\n",
    "            \n",
    "            #print(W_out.shape)\n",
    "            #self.W_out = W_out\n",
    "            \n",
    "        #print(self.W_out.shape)\n",
    "            \n",
    "        #return self.W_out\n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        V, F, D = X.shape\n",
    "        pred = np.zeros((V, F, 1))\n",
    "        probs = np.zeros((V, F, 1))\n",
    "        for v in range(V):\n",
    "            states = self.update(X[v])\n",
    "            \n",
    "            \n",
    "            for f in range(F):\n",
    "                state = states[f]\n",
    "                output = np.dot(state.reshape(-1, 1).T, self.W_out.reshape(self.reservoir_size, -1))\n",
    "                y_prob = sigmoid(output)\n",
    "                pred[v][f] = (y_prob >= self.threshold).astype(int)\n",
    "                #print(pred[v][f].shape)\n",
    "                probs[v][f] =  y_prob\n",
    "        \n",
    "        return pred, probs\n",
    "            \n",
    "            \n",
    "            #print(states.shape)\n",
    "            #y = states @ self.W_out[v].T\n",
    "            #print(y.shape)\n",
    "            #print(self.W_out.shape)\n",
    "            #print(\"W_out\", self.W_out[v].shape)\n",
    "            #print(\"states\", states.shape)\n",
    "            \n",
    "            #w = self.W_out[v].reshape(self.reservoir_size, 1)\n",
    "            #y_pred[v] = sigmoid(np.sum(w * states.reshape((1, F, self.reservoir_size, 1)), axis=2))\n",
    "\n",
    "            #print(\"New W: \", w.shape)\n",
    "            #w = self.W_out[v].reshape((1, F, self.reservoir_size, 1))\n",
    "            #s = states.reshape((1, F, self.reservoir_size, 1))\n",
    "            #print(\"w\", w.shape)\n",
    "            #print(\"s\", s.shape)\n",
    "            \n",
    "            #y_prob = np.zeros((F, 1))\n",
    "            #y_pred = np.dot(self.W_out, states.T)\n",
    "            #y_prob = softmax(y_pred)\n",
    "            #y_pred_labels = np.argmax(y_prob, axis=1)\n",
    "            #for t in range(F):\n",
    "            #    y_pred = np.dot(self.W_out, states[t])\n",
    "            #    y_prob[t] = sigmoid(y_pred)\n",
    "                \n",
    "            #y_prob = sigmoid(y_pred)\n",
    "            #print(y_prob.T.shape)\n",
    "            #probs[v] = y_prob.reshape(-1, 1)\n",
    "            #print(y_pred[2])\n",
    "            #print(\"y_pred\", y_pred.reshape(-1, 1).shape)\n",
    "            \n",
    "            #y_pred = softmax(self.W_out[v] @ states.T)\n",
    "            #print(y_pred.shape)\n",
    "            #pred[v] = (y_prob.reshape(-1, 1) >= self.threshold).astype(int)\n",
    "            \n",
    "            \n",
    "        #return pred, probs\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a332a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "param_grid = {'alpha': [0.1, 1, 10, 100]}\n",
    "\n",
    "# Create a Ridge regression object\n",
    "ridge = Ridge()\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=ridge, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(pca_400_train, labels_train)\n",
    "\n",
    "# Print the best value of the alpha hyperparameter found by GridSearchCV\n",
    "print(\"Best alpha value: \", grid_search.best_params_['alpha'])\n",
    "\n",
    "# Use the best value of alpha to fit the Ridge regression model to the training data\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "ridge = Ridge(alpha=best_alpha)\n",
    "ridge.fit(pca_400_train, labels_train)\n",
    "\n",
    "# Predict on the test data using the fitted model\n",
    "y_pred = ridge.predict(pca_400_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3039fe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "vids_frames, dim = pca_400_train.shape\n",
    "vids = int(vids_frames/200)\n",
    "frames = 200\n",
    "data = pca_400_train.reshape(vids, frames, dim)\n",
    "\n",
    "X_train_new, X_val, y_train_new, y_val = train_test_split(data, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1867b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "VF, D = pca_400_train.shape\n",
    "V = int(VF/200)\n",
    "F = 200\n",
    "train_data = pca_400_train.reshape(V, F, D)\n",
    "\n",
    "print(train_data.shape)\n",
    "\n",
    "#train_states = None\n",
    "\n",
    "    \n",
    "VF, D = pca_400_test.shape\n",
    "V = int(VF/200)\n",
    "F = 200\n",
    "test_data = pca_400_test.reshape(V, F, D)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1421a819",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11200, 1, 160, 240)\n",
      "(11200, 1)\n",
      "3569.0 0.31866071428571424 0.6813392857142857\n",
      "0 0.3002100225005831 0.6813392857142857 0.5 0.1809632485466344 0.8442857142857143 0.0 0.0\n",
      "1 0.2983265572360584 0.7066964285714286 0.5542542274310678 0.1797019908470767 0.8057142857142857 0.22541853336477247 0.2860892388451443\n",
      "2 0.2964119767504079 0.7405357142857143 0.6583583008638247 0.17850601247378758 0.7860714285714285 0.5146960587842353 0.45594913714804725\n",
      "3 0.29433842056563925 0.7244642857142857 0.6746037705325114 0.17723691303815162 0.765 0.5540462427745665 0.4835164835164836\n",
      "4 0.2920409286660807 0.7050892857142858 0.6769406682325662 0.1759514319045203 0.7528571428571429 0.5643055005935893 0.5\n",
      "5 0.2895399390586785 0.6925892857142857 0.6808178427796634 0.17457229750497 0.7421428571428571 0.5734109775740304 0.5095108695652174\n",
      "6 0.28684330944504055 0.6885714285714286 0.6865943904100891 0.17313203002725328 0.74 0.5822754491017965 0.5315315315315315\n",
      "7 0.2840289920568466 0.686875 0.6917627509180362 0.1717379918055875 0.73 0.5893923428170004 0.5333333333333333\n",
      "8 0.28118130777563366 0.6895535714285714 0.7009620033956991 0.1703940582062517 0.7182142857142857 0.6005743825387708 0.5244122965641952\n",
      "9 0.27832742940102306 0.6925 0.7095375189291999 0.168968137885843 0.7107142857142857 0.6105834464043418 0.5184304399524375\n",
      "10 0.27547411088432583 0.694375 0.7144184188610856 0.16771877131291799 0.7 0.6161264999439274 0.5093457943925234\n",
      "11 0.2726417662841933 0.6976785714285715 0.7196765167106975 0.16647117052759444 0.6892857142857143 0.6219294327824921 0.5005740528128587\n",
      "12 0.2698222090091024 0.7020535714285714 0.7255717349991677 0.16535243232335364 0.6721428571428572 0.6283550506737943 0.48715083798882686\n",
      "13 0.26704108874712673 0.7047321428571428 0.7299237390480696 0.1642424070409366 0.6639285714285714 0.6330855431044047 0.48097076668505234\n",
      "14 0.26426930565919193 0.7082142857142857 0.7331502627919864 0.16331178003123828 0.6582142857142858 0.6365658362989325 0.4767632586112629\n",
      "15 0.2615217300398009 0.7128571428571429 0.7385708902417947 0.16226960771850177 0.6535714285714286 0.6424282855236825 0.4733984799131379\n",
      "16 0.25878729538193773 0.7173214285714286 0.7433384618982921 0.1613067915397031 0.6489285714285714 0.6475957257346394 0.47008086253369274\n",
      "17 0.25608085468411446 0.7209821428571429 0.7475163336465205 0.16037654876708984 0.6446428571428572 0.6521206723811643 0.46705945366898766\n",
      "18 0.25338515053902355 0.7249107142857143 0.7512941876088373 0.15951817056962422 0.6403571428571428 0.6562534865558406 0.4640766365087812\n",
      "19 0.25069453274565084 0.7295535714285715 0.7554470731618926 0.15864652448466846 0.6375 0.660844250363901 0.4621091679915209\n",
      "20 0.24803148289876326 0.7340178571428572 0.7595434873436384 0.15787592051284655 0.6357142857142857 0.6653936875210603 0.46088794926004223\n",
      "21 0.24537293586347783 0.73625 0.761852700119137 0.1570153497159481 0.6317857142857143 0.6679406474820143 0.45822385706778773\n",
      "22 0.24271919658141478 0.7415178571428571 0.7665388142091516 0.15627469069191388 0.6307142857142857 0.6732136810023704 0.45750262329485836\n",
      "23 0.24008838858987605 0.7460714285714286 0.7707753236556776 0.1555583548865148 0.6314285714285715 0.6779891304347826 0.4579831932773109\n",
      "24 0.2374715403254543 0.750625 0.7756084175242047 0.15480139718524047 0.6317857142857143 0.6833692325133204 0.45822385706778773\n",
      "25 0.2348597701638937 0.7554464285714285 0.7807872241343219 0.15411505049892835 0.6303571428571428 0.6891385767790262 0.4572627163083377\n",
      "26 0.23227194217698915 0.7596428571428572 0.7849853638909788 0.15346419039581502 0.6296428571428572 0.6938821924039117 0.45678365636458884\n",
      "27 0.22969998472503253 0.76375 0.7888942622773553 0.15269051917961665 0.6310714285714286 0.698358413132695 0.45774278215223096\n",
      "28 0.22713316418230534 0.7677678571428571 0.7934087959264534 0.15205738507211208 0.6307142857142857 0.7033869312350325 0.45750262329485836\n",
      "29 0.2245767739202295 0.7702678571428572 0.796138294496292 0.15146042459777423 0.6314285714285715 0.7064460924130063 0.4579831932773109\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, hidden_size_1=1000, hidden_size_2=200):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=11, stride=4, padding=5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=5, stride=4, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        self.fc1 = nn.Linear(16*10*15, hidden_size_1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        hidden = self.relu3(x)\n",
    "        x = self.fc2(hidden)\n",
    "        x = self.relu4(x)\n",
    "        return hidden, x\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "Nf = 200\n",
    "H = 160\n",
    "W = 240\n",
    "batch_size = 200\n",
    "\n",
    "Nv_train = len(X_train)\n",
    "Nv_test = len(X_test)\n",
    "\n",
    "\n",
    "\n",
    "x_train_mean = X_train.mean(axis=0)\n",
    "x_train_nomean = X_train - x_train_mean\n",
    "x_test_nomean = X_test - x_train_mean\n",
    "\n",
    "\n",
    "x_train_nomean = x_train_nomean.reshape(Nv_train*Nf, 1, H, W)\n",
    "y_train = y_train.reshape(Nv_train*Nf, 1)\n",
    "print(x_train_nomean.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "train_Ntrue = y_train.sum()\n",
    "train_c1_w = 1.0/train_Ntrue\n",
    "train_c0_w = 1.0/(len(y_train) - train_Ntrue)\n",
    "train_c_wtot = train_c1_w + train_c0_w\n",
    "train_c1_w /= train_c_wtot\n",
    "train_c0_w /= train_c_wtot\n",
    "\n",
    "train_c_w = (1-y_train)*train_c0_w + y_train*train_c1_w\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(train_Ntrue, train_c0_w, train_c1_w)\n",
    "\n",
    "trainset = TensorDataset(torch.Tensor(x_train_nomean).to(device), torch.Tensor(y_train).to(device), torch.Tensor(train_c_w).to(device))\n",
    "train_dl = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "x_test_nomean = x_test_nomean.reshape(Nv_test*Nf, 1, H, W)\n",
    "y_test = y_test.reshape(Nv_test*Nf, 1)\n",
    "\n",
    "test_Ntrue = y_test.sum()\n",
    "test_c1_w = 1.0/test_Ntrue\n",
    "test_c0_w = 1.0/(len(y_test) - test_Ntrue)\n",
    "test_c_wtot = test_c0_w + test_c1_w\n",
    "test_c1_w /= test_c_wtot\n",
    "test_c0_w /= test_c_wtot\n",
    "\n",
    "test_c_w = (1-y_test)*test_c0_w + y_test*test_c1_w\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "testset = TensorDataset(torch.Tensor(x_test_nomean).to(device), torch.Tensor(y_test).to(device), torch.Tensor(test_c_w).to(device))\n",
    "test_dl = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#model = nn.Sequential(\n",
    "#            nn.Conv2d(1, 16, 11, padding=5, stride=4),\n",
    "#            nn.ReLU(),\n",
    "#            nn.Conv2d(16, 16, 5, padding=2, stride=4),\n",
    "#            nn.ReLU(),\n",
    "#            nn.Flatten(start_dim=1),\n",
    "#            nn.Linear(16*10*15, 1000),\n",
    "#            nn.ReLU(),\n",
    "#            nn.Linear(1000, 200),\n",
    "#            nn.ReLU(),\n",
    "#            nn.Linear(200,1),\n",
    "#            nn.Sigmoid()\n",
    "#        )\n",
    "\n",
    "hidden_size_1 = 1000\n",
    "hidden_size_2 = 200\n",
    "model = nn.Sequential(\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(240*160, hidden_size_1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size_1, hidden_size_2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size_2, 1),\n",
    "            nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "lr = 1e-6\n",
    "weight_decay = 1e-3\n",
    "\n",
    "#loss_criterion = nn.MSELoss() \n",
    "#loss_criterion = nn.BCELoss() \n",
    "#loss_criterion = lambda pred, true, weight: weight*\n",
    "loss_criterion = F.binary_cross_entropy\n",
    "optimiser = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "Nepochs=30\n",
    "\n",
    "\n",
    "\n",
    "tr_preds = np.zeros((len(train_dl), batch_size, 1))\n",
    "tr_trues = np.zeros((len(train_dl), batch_size, 1))\n",
    "\n",
    "te_preds = np.zeros((len(test_dl), batch_size, 1))\n",
    "te_trues = np.zeros((len(test_dl), batch_size, 1))\n",
    "\n",
    "for n in range(Nepochs):\n",
    "    model.train()\n",
    "    tr_avg_loss = 0.0\n",
    "    tr_avg_acc = 0.0\n",
    "    \n",
    "    for i,batch in enumerate(train_dl):\n",
    "        x, y_true, c_w = batch\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        c_w = c_w.to(device)\n",
    "        optimiser.zero_grad()\n",
    "        y = model(x)\n",
    "        loss = loss_criterion(y, y_true, weight=c_w)\n",
    "        pred_class = (y > 0.5)\n",
    "        true_class = (y_true > 0.5)\n",
    "        tr_avg_acc += (pred_class == true_class).sum().item()\n",
    "\n",
    "        tr_preds[i] = pred_class.detach().cpu().numpy()\n",
    "        tr_trues[i] = true_class.detach().cpu().numpy()\n",
    "\n",
    "        tr_avg_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "    tr_avg_loss /= len(train_dl)\n",
    "    tr_avg_acc /= len(train_dl)*batch_size\n",
    "\n",
    "    tr_prec = precision_score(tr_trues.flatten(), tr_preds.flatten(), zero_division=0)\n",
    "    tr_recall = recall_score(tr_trues.flatten(), tr_preds.flatten(), zero_division=0)\n",
    "    tr_f1 = f1_score(tr_trues.flatten(), tr_preds.flatten(), zero_division=0)\n",
    "    tr_bal_acc = balanced_accuracy_score(tr_trues.flatten(), tr_preds.flatten())\n",
    "\n",
    "    model.eval()\n",
    "    te_avg_loss = 0.0\n",
    "    te_avg_acc = 0.0\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(test_dl):\n",
    "            x, y_true, c_w = batch\n",
    "            y = model(x)\n",
    "            loss = loss_criterion(y, y_true, weight=c_w)\n",
    "            te_avg_loss += loss.item()\n",
    "            pred_class = (y > 0.5)\n",
    "            true_class = (y_true > 0.5)\n",
    "            te_avg_acc += (pred_class == true_class).sum().item()\n",
    "            te_preds[i] = pred_class.detach().cpu().numpy()\n",
    "            te_trues[i] = true_class.detach().cpu().numpy()\n",
    "    te_avg_loss /= len(test_dl)\n",
    "    te_avg_acc /= len(test_dl)*batch_size\n",
    "    \n",
    "    te_prec = precision_score(te_trues.flatten(), te_preds.flatten(), zero_division=0)\n",
    "    te_recall = recall_score(te_trues.flatten(), te_preds.flatten(), zero_division=0)\n",
    "    te_f1 = f1_score(te_trues.flatten(), te_preds.flatten(), zero_division=0)\n",
    "    te_bal_acc = balanced_accuracy_score(te_trues.flatten(), te_preds.flatten())\n",
    "\n",
    "    print(n, tr_avg_loss, tr_avg_acc, tr_bal_acc, te_avg_loss, te_avg_acc, tr_f1, te_f1)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "735573de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11200, 200])\n",
      "[[[-0.04791306  0.08221364  0.09610893 ...  0.07777058  0.20557433\n",
      "    0.02142078]\n",
      "  [-0.0446519   0.09179939  0.10708374 ...  0.08372323  0.21667466\n",
      "    0.02303589]\n",
      "  [-0.04552879  0.10102428  0.11332078 ...  0.09372257  0.21853474\n",
      "    0.01596302]\n",
      "  ...\n",
      "  [ 0.0147739   0.0026508  -0.00182119 ... -0.0159204   0.07068056\n",
      "    0.07757584]\n",
      "  [ 0.00785     0.00594202 -0.00549462 ... -0.01212717  0.07161111\n",
      "    0.08939582]\n",
      "  [-0.00309217  0.00530974 -0.01408747 ... -0.01827993  0.07337344\n",
      "    0.09208953]]\n",
      "\n",
      " [[ 0.09256408  0.00186871  0.03756487 ...  0.01919756 -0.02202162\n",
      "    0.07445326]\n",
      "  [ 0.08517784  0.01048691  0.05644045 ...  0.03189922 -0.00328935\n",
      "    0.06124849]\n",
      "  [ 0.07367271  0.03996683  0.0754344  ...  0.03738303  0.0425359\n",
      "    0.03152732]\n",
      "  ...\n",
      "  [ 0.08620501 -0.0864313   0.00181089 ... -0.0320107  -0.06218306\n",
      "    0.01836212]\n",
      "  [ 0.0890402  -0.0912032   0.00232181 ... -0.04064516 -0.05933046\n",
      "    0.02885289]\n",
      "  [ 0.11064216 -0.10757339  0.00053005 ... -0.04929985 -0.06528173\n",
      "    0.05398834]]\n",
      "\n",
      " [[-0.03790503  0.07914748  0.07500839 ...  0.07637633  0.13842419\n",
      "    0.04717143]\n",
      "  [-0.0354058   0.09587944  0.0953251  ...  0.08596047  0.1430204\n",
      "    0.03898391]\n",
      "  [-0.04167227  0.10781112  0.1052032  ...  0.09095445  0.15267977\n",
      "    0.03969331]\n",
      "  ...\n",
      "  [-0.07004035 -0.0839065  -0.03347634 ... -0.07500522  0.01082702\n",
      "    0.08074392]\n",
      "  [-0.0707012  -0.08702055 -0.03302732 ... -0.06983013  0.01451154\n",
      "    0.07671505]\n",
      "  [-0.06090952 -0.07614493 -0.02657155 ... -0.07256555  0.01638545\n",
      "    0.07706672]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.12374601  0.23537597  0.2761783  ...  0.19312719  0.3469364\n",
      "    0.14759043]\n",
      "  [ 0.09240782  0.2205544   0.26940945 ...  0.17980832  0.3357812\n",
      "    0.14108646]\n",
      "  [ 0.07221188  0.19552243  0.2585237  ...  0.1595563   0.32297823\n",
      "    0.13363779]\n",
      "  ...\n",
      "  [-0.07308378  0.07489067  0.00741984 ...  0.0292336   0.07802522\n",
      "    0.04978227]\n",
      "  [-0.07828014  0.08391056  0.00213098 ...  0.02178111  0.0778912\n",
      "    0.0563554 ]\n",
      "  [-0.07012808  0.07101226 -0.00098638 ...  0.01203232  0.07021198\n",
      "    0.06259585]]\n",
      "\n",
      " [[ 0.15664104  0.04040703 -0.02568024 ... -0.07081775 -0.17922077\n",
      "    0.12055157]\n",
      "  [ 0.16060165  0.04549518 -0.02278464 ... -0.06335831 -0.18127495\n",
      "    0.12317815]\n",
      "  [ 0.14598338  0.05230921 -0.02116941 ... -0.06404354 -0.18130997\n",
      "    0.11561673]\n",
      "  ...\n",
      "  [ 0.12038696  0.09615698 -0.03663747 ... -0.09548436 -0.17505671\n",
      "    0.11348026]\n",
      "  [ 0.10410898  0.10220776 -0.02773867 ... -0.09058963 -0.16605239\n",
      "    0.10713696]\n",
      "  [ 0.09304009  0.12160158 -0.03270512 ... -0.09154359 -0.15969098\n",
      "    0.09209189]]\n",
      "\n",
      " [[-0.04824094 -0.05628667  0.01384394 ... -0.04081038  0.05250918\n",
      "    0.08472773]\n",
      "  [-0.05305498 -0.0593544   0.01190086 ... -0.04421834  0.0411958\n",
      "    0.08070555]\n",
      "  [-0.05340315 -0.06121416  0.01321052 ... -0.04423039  0.03011561\n",
      "    0.07860912]\n",
      "  ...\n",
      "  [-0.00408532 -0.00330269  0.02590322 ... -0.01051938  0.00259151\n",
      "   -0.01034687]\n",
      "  [-0.00666698 -0.00873839  0.02738021 ... -0.01415304  0.00172787\n",
      "   -0.00701591]\n",
      "  [-0.00872118 -0.00948131  0.02778001 ... -0.01840421  0.00557123\n",
      "   -0.0055431 ]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_extractor = nn.Sequential(*list(model.children())[:-3])\n",
    "hidden_representation_train = feature_extractor(torch.Tensor(x_train_nomean).to(device))\n",
    "hidden_representation_test = feature_extractor(torch.Tensor(x_test_nomean).to(device))\n",
    "\n",
    "print(hidden_representation_train.shape)\n",
    "#print(hidden_representation)\n",
    "#print(x_test_nomean.reshape(Nv, Nf, ))\n",
    "\n",
    "\n",
    "esn_input_train = hidden_representation_train.cpu().detach().numpy().reshape(56, 200, 200)\n",
    "esn_input_test = hidden_representation_test.cpu().detach().numpy().reshape(14, 200, 200)\n",
    "\n",
    "y_train = y_train.reshape(56, 200, 1)\n",
    "y_test = y_test.reshape(14, 200, 1)\n",
    "print(esn_input_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7a27624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vids_frames, dim = esn_input_train.shape\n",
    "#vids = int(vids_frames/200)\n",
    "#frames = 200\n",
    "#data = esn_input_train.reshape(vids, frames, dim)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train_opt, X_val, y_train_opt, y_val = train_test_split(esn_input_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdd03ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "input_size = 200\n",
    "reservoir_size = 1000\n",
    "output_size = 1\n",
    "\n",
    "\n",
    "#np.random.seed(75)\n",
    "\n",
    "\n",
    "#def prune(trial):\n",
    "#    if trial.intermediate_values:\n",
    "#        last_value = list(trial.intermediate_values.values())[-1]\n",
    "#        if last_value < 0.65:\n",
    "#            return True\n",
    "#    return False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the search space for hyperparameters\n",
    "    #reservoir_size = trial.suggest_int(\"reservoir_size\", 700, 1500)\n",
    "    spectral_radius = trial.suggest_float(\"spectral_radius\", 0.0, 1.0)\n",
    "    sparsity = trial.suggest_float(\"sparsity\", 0.0, 0.2)\n",
    "    leaking_rate = trial.suggest_float(\"leaking_rate\", 0.8, 0.99)\n",
    "    input_scaling = trial.suggest_float(\"input_scaling\", 0.1, 5.0)\n",
    "    threshold = trial.suggest_float(\"threshold\", 0.4, 1.0)\n",
    "    ridge_alpha = trial.suggest_float(\"ridge_alpha\", 0.0001, 1.0)\n",
    "    #random_seed = trial.suggest_int(\"random_seed\", 1, 200)\n",
    "\n",
    "    # Initialize the ESN with the given hyperparameters\n",
    "    #esn = ESN(input_size=input_size, reservoir_size=reservoir_size, output_size=output_size, \n",
    "    #          leaking_rate=leaking_rate, spectral_radius=spectral_radius, input_scaling=input_scaling, \n",
    "    #          threshold=threshold, sparsity=sparsity, ridge_alpha=ridge_alpha)\n",
    "    \n",
    "    \n",
    "    esn = ESN(input_size=input_size, reservoir_size=reservoir_size, output_size=output_size, \n",
    "              leaking_rate=leaking_rate, spectral_radius=spectral_radius, input_scaling=input_scaling, sparsity=sparsity, \n",
    "              ridge_alpha=ridge_alpha, random_seed=83)\n",
    "    \n",
    "    #esn = ESN(input_size=input_size, reservoir_size=reservoir_size, output_size=output_size,\n",
    "    #         leaking_rate=0.95, sparsity=0.1, random_seed=random_seed)\n",
    "\n",
    "    # Train and evaluate the ESN on the training set\n",
    "    esn.fit(X_train_opt, y_train_opt)\n",
    "    y_pred, y_prob = esn.predict(X_val)\n",
    "    score = balanced_accuracy_score(y_val.flatten(), y_pred.flatten())\n",
    "    print(\"F1: \", f1_score(y_val.flatten(), y_pred.flatten()))\n",
    "    print(\"AUC: \", roc_auc_score(y_val.flatten(), y_prob.flatten()))\n",
    "    \n",
    "    #trial_number = trial.number\n",
    "    #if prune(trial):\n",
    "    #    raise optuna.exceptions.TrialPruned()\n",
    "    #print(trial.params, score)\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# Run the optimization\n",
    "study.optimize(objective, n_trials=100, n_jobs=-1)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "best_params = study.best_params\n",
    "best_score = study.best_value\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "print(f\"Best score: {best_score}\")\n",
    "optuna.visualization.plot_param_importances(study)\n",
    "plot_optimization_history(study)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e5280eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a077d1b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual anomalies:  436\n",
      "Predicted anomalies 0\n",
      "[0.39656924 0.39660611 0.40536264 ... 0.58792459 0.50330867 0.41144512]\n",
      "Pred (14, 200, 1)\n",
      "Pred flattened (2800,)\n",
      "y_test (14, 200, 1)\n",
      "y_test flattened (2800,)\n",
      "Bal Acc:  0.5\n",
      "F1:  0.0\n",
      "AUC:  0.7202766264611372\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x260e3d52c50>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#esn = ESN(input_size=400, reservoir_size=500, output_size=1, alpha=0.5, gamma=0.1, spectral_radius=0.95, sparsity=0.1)\n",
    "#esn = ESN(input_scaling=0.6075448519014384, input_size=400,\n",
    "    #leaking_rate=0.17052412368729153, output_size=1, reservoir_size=1000,\n",
    "    #sparsity=0.06505159298527952, spectral_radius=0.9488855372533332,\n",
    "    #threshold=0.9656320330745594)\n",
    "    \n",
    "#np.random.seed(42)\n",
    "#esn = ESN(input_scaling=0.6998812876189486, input_size=400,\n",
    "#    leaking_rate=0.08210799041387684, output_size=1, reservoir_size=1000,\n",
    "#    sparsity=0.9252733800015754, spectral_radius=0.3364410948180354, threshold=0.39462707778742845)\n",
    "\n",
    "#0.9219100448194322\n",
    "\n",
    "\n",
    "esn = ESN(input_size=200, reservoir_size=1000, output_size=1, leaking_rate=0.890752732058367, spectral_radius=0.5215203845623011,\n",
    "         sparsity=0.08860864301501147, input_scaling=4.919175568058266, threshold=0.7, ridge_alpha=0.6669484997770273, random_seed=83)\n",
    "\n",
    "\n",
    "\n",
    "#train_ESN(esn, pca_400, labels, epochs)\n",
    "\n",
    "\n",
    "# ESN trained using dataset as shape (V*F, D)\n",
    "#train_states = esn.fit(pca_400_train, labels_train)\n",
    "#y_pred = esn.predict(pca_400_test)\n",
    "#esn_accuracy = recall_score(labels_test, y_pred)\n",
    "#print(\"ESN Accuracy: \", esn_accuracy)\n",
    "#auc_score = roc_auc_score(labels_test, y_pred)\n",
    "#print(\"ESN AUC: \", auc_score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Trained using (V, F, D)\n",
    "#VF, D = pca_400_train.shape\n",
    "#V = int(VF/200)\n",
    "#F = 200\n",
    "#train_data = pca_400_train.reshape(V, F, D)\n",
    "\n",
    "#train_states = None\n",
    "\n",
    "\n",
    "\n",
    "esn.fit(esn_input_train, y_train)\n",
    "    \n",
    "#VF, D = pca_400_test.shape\n",
    "#V = int(VF/200)\n",
    "#F = 200\n",
    "#test_data = pca_400_test.reshape(V, F, D)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#acc = np.zeros((V))\n",
    "#for i in range(V):\n",
    "#    y_pred = esn.predict(test_data[i])\n",
    "#    esn_accuracy = recall_score(y_test[i], y_pred)\n",
    "#    acc[i] = esn_accuracy\n",
    "#    if 1 in y_test[i]:\n",
    "#        auc_score = roc_auc_score(y_test[i], y_pred)\n",
    "#        print(f\"Accuracy for video {i}: {esn_accuracy}     AUC for video {i}: {auc_score}\")\n",
    "#    else:\n",
    "#        print(f\"Accuracy for video {i}: {esn_accuracy}\")\n",
    "\n",
    "\n",
    "#print(np.mean(acc))\n",
    "\n",
    "\n",
    "\n",
    "esn_pred, prob = esn.predict(esn_input_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test.flatten(), prob.flatten())\n",
    "auc_score = roc_auc_score(y_test.flatten(), prob.flatten())\n",
    "\n",
    "\n",
    "print(\"Actual anomalies: \", np.count_nonzero(y_test.flatten()))\n",
    "print(\"Predicted anomalies\", np.count_nonzero(esn_pred.flatten()))\n",
    "print(prob.flatten())\n",
    "print(\"Pred\", esn_pred.shape)\n",
    "print(\"Pred flattened\", esn_pred.flatten().shape)\n",
    "print(\"y_test\", y_test.shape)\n",
    "print(\"y_test flattened\", y_test.flatten().shape)\n",
    "#print((prob >= 0.5).astype(int))\n",
    "\n",
    "#print(esn_pred.flatten())\n",
    "#print(y_test.flatten())\n",
    "balanced_accuracy = balanced_accuracy_score(y_test.flatten(), esn_pred.flatten())\n",
    "print(\"Bal Acc: \", balanced_accuracy)\n",
    "print(\"F1: \", f1_score(y_test.flatten(), esn_pred.flatten()))\n",
    "print(\"AUC: \", auc_score)\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title(f'ROC Curve (AUC = {auc_score:.2f})')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test.flatten(), esn_pred.flatten())\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#esn_accuracy = accuracy_score(y_test, y_pred)\n",
    "#print(\"ESN Accuracy: \", esn_accuracy)\n",
    "#auc_score = roc_auc_score(y_test, y_pred)\n",
    "#print(\"ESN AUC: \", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238f842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9793b718",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7af8d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
